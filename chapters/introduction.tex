\chapter{Introduction}

As the world becomes increasingly interconnected, the ability to observe and analyze our environment from space has emerged as one of the most important tools in addressing global challenges. From this perspective, satellite missions, through their advanced sensor systems, allow the collection of information about the Earth's surface, providing the most detailed and extensive view of the processes of change on our planet. Among the key disciplines that enable these functions, remote sensing stands out, transforming the data obtained by these sensors into critical information for solving environmental and social issues. This discipline provides specific analyses of the transformations and characteristics of certain geographic areas. With advancements in AI (Artificial Intelligence), analytical capabilities have reached a new level, allowing almost any type of satellite image to be analyzed with unprecedented precision and efficiency.

Spatial resolution is a fundamental parameter for the analysis of remote sensing images. It is defined as the minimum ground distance that separates two independent objects that can be distinguished. The factors that determine it include altitude, distance, and the quality of the instruments used \autocite{alparone2015remote}. Another important factor related to spatial resolution is Ground Sampling Distance (GSD), which is the portion of the Earth's surface represented by each pixel \autocite{lillesand2015remote}.

One of the most widely used sensors due to its high spatial resolution is the Sentinel-2 MSI, operated by the European Space Agency \autocite{Sentinel2_Handbook}. Since its launch in June 2015, it has provided open-access multispectral images, generating significant interest in the scientific community and various industries, becoming a key tool for providing data in applications such as land use monitoring, change detection, and vegetation analysis. The sensor is equipped with 13 spectral bands distributed in three spatial resolutions: 4 spectral bands with a resolution of 10 m, 6 spectral bands with 20 m, and 3 spectral bands with 60 m, designed for the collection of various topographic parameters \autocite{lanaras2018super}. This spectral diversity enables detailed studies on a wide range of terrestrial phenomena by combining specific bands, from water quality assessment to snow surface monitoring.

Another sensor that stands out for its higher resolution is the National Agriculture Imagery Program (NAIP), which provides aerial images with a resolution of up to 1 meter. Although its coverage is limited to the continental United States, it offers aerial images with a spatial resolution of up to 1 meter, making it an important source for studies requiring a higher level of detail. NAIP captures images during the peak agricultural activity months, from June to August, and provides updates every three years (previously every five years before 2009). Since 2011, the images have consistently included RGB and NIR bands, improving their quality and applicability in areas such as urban planning and agricultural monitoring. Although NAIP and Sentinel-2 have different approaches and scopes, the combination of images from both sensors allows for a greater richness of data, which is crucial for studies requiring both extensive coverage and exceptional detail.

There are various techniques to address the limitation of spatial and spectral resolution in satellite images within the field of remote sensing, from traditional image fusion methods to more recent approaches based on artificial intelligence. Among the latter, deep learning has proven to be especially promising \autocite{gargiulo2019fast}. One of the most effective applications of this technique is super-resolution, which seeks to increase the spatial resolution of images by generating additional details from existing data. These machine learning techniques allow for the reconstruction of higher-resolution images from lower-quality versions, optimizing both spatial precision and spectral coherence.

\section{Motivation}

The development of techniques to improve the resolution of images obtained by the Sentinel-2 sensor has been a significant challenge in the scientific community. In this process, advanced deep learning architectures such as Generative Adversarial Networks (GANs) and Convolutional Neural Networks (CNNs) play a crucial role, efficiently managing the data \autocite{salgueiro2020super}. Achieving an increase in spatial resolution while maintaining spectral coherence and optimizing data quality opens new frontiers in satellite image analysis.

The availability of free and high-quality images, such as those provided by Sentinel-2, is a valuable resource for scientific research. Although there are other ways to obtain high-resolution images, they often do not cover as large areas or have the necessary temporal resolution for certain studies. Thanks to its global coverage and high revisit frequency, this sensor offers a significant advantage in this regard. Improving its resolution would allow for more detailed studies without the need to resort to costly sensors, making the available data even more impactful.

Additionally, this work seeks to contribute to the advancement of AI in remote sensing applications. By using innovative architectures, this research has the potential to open new possibilities for improving satellite image resolution. This approach not only benefits current science but also has the potential to inspire future research, allowing the continued development of these techniques in new contexts.

\section{Problem Statement}

Despite the availability of advanced super-resolution models \autocite{salgueiro2020super, navarro_s√°nchez_2020}, the main challenge lies in ensuring that the resulting images not only improve spatial resolution but also maintain spectral coherence, a crucial factor in scientific applications. To overcome the spatial resolution limitations of sensors like Sentinel-2, this work proposes the use of advanced super-resolution techniques based on deep learning models. Super-resolution has become a powerful tool for enhancing image quality, using architectures such as Convolutional Neural Networks (CNNs) and Generative Adversarial Networks (GANs) to generate high-resolution images while preserving spectral and spatial coherence. These techniques, applied to Sentinel-2 multispectral images, have the potential to produce results comparable to those obtained with higher-resolution sensors like NAIP, but with the advantage of working with more accessible data.

In various studies, the Wald Protocol has been followed, a standard in the field of remote sensing, to validate the quality of super-resolved images. This protocol establishes rigorous criteria that ensure the enhanced images maintain spectral and spatial consistency with the original images. In this work, a super-resolution (SR) model is proposed that transforms the 10m and 20m bands of Sentinel-2 into higher-resolution images (2.5m), preserving critical spectral details for precise studies. The enhancement process includes an intermediate step of super-resolution from 10m to 40m, which strengthens the model's robustness.

Furthermore, the use of the Wald Protocol ensures that the fused images retain both spatial and spectral integrity, validating their quality. This approach, which separates the image fusion and resolution enhancement processes through super-resolution, allows each stage to work independently, increasing the versatility and applicability of the proposed method for different types of sensors and applications.

This research not only aims to advance the field of image super-resolution but also offers a viable and accessible solution for projects that require high-resolution images but must operate within the economic and technical limitations of current sensors.

\section{Structure of the Work}

In \textbf{Chapter One}, the purpose and motivation of the work are established. The problem addressed focuses on the need to improve the spatial resolution of satellite images, specifically those from Sentinel-2, through super-resolution techniques. The chapter also describes the organization of the thesis, outlining the main sections and objectives.

\textbf{Chapter Two} delves into a detailed analysis of the context, examining the current state of satellite imaging technologies and the demand for high-resolution data in various fields, such as environmental monitoring and urban planning. The benefits and challenges of improving spatial resolution through multispectral data fusion and super-resolution models are discussed, with a focus on the limitations of existing techniques.

\textbf{Chapter Three} reviews the state of the art in super-resolution technologies applied to satellite images. The chapter provides an overview of key methods such as pansharpening, image model inversion, and deep learning approaches. It also highlights the importance of the Wald Protocol as a validation framework to ensure spectral and spatial consistency in the generated high-resolution images.

In \textbf{Chapter Four}, the general and specific objectives of the project are defined. The main objective is to develop a super-resolution model capable of improving Sentinel-2 images from 10m and 20m resolution to 2.5m resolution using a combination of Convolutional Neural Network (CNN) models and multispectral data fusion techniques. The methodology section details the process followed for model training, dataset preparation, and evaluation using the Wald Protocol.

\textbf{Chapter Five} presents the functional and non-functional requirements of the super-resolution system. Functional requirements include the ability to handle multispectral images of various resolutions and generate consistent, high-quality results with a resolution of 2.5m. Non-functional requirements focus on the system's efficiency, scalability, and robustness in handling large datasets.

In \textbf{Chapter Six}, the development of the super-resolution model is explained in detail. This includes the training process, the design of the neural network architectures (Fusion X2 and X4 models), and the integration of deep learning techniques. The limitations encountered during the training phase, such as memory constraints and model performance, are discussed along with potential optimizations.

\textbf{Chapter Seven} evaluates the performance of the developed model, comparing it with existing techniques. The evaluation is based on both qualitative and quantitative metrics, focusing on the spatial and spectral fidelity of the generated high-resolution images. The chapter also includes an analysis of the system's usability and its potential impact on real-world applications, such as precision agriculture and land use monitoring.

\textbf{Chapter Eight} concludes the work by summarizing the main contributions of the thesis and proposing future research directions. Possible improvements include refining the deep learning architecture, exploring other fusion techniques, and applying the model to different types of satellite images.

\textbf{Appendix I} includes output images generated by the super-resolution model, demonstrating the improved resolution for various Sentinel-2 bands.

\textbf{Appendix II} presents the results of the Wald Protocol validation tests, showing the system's performance in maintaining spectral and spatial consistency.

\textbf{Appendix III} provides detailed documentation of the software tools and libraries used for the model's implementation.

\textbf{Appendix IV} contains the research paper associated with this thesis, submitted for publication.
